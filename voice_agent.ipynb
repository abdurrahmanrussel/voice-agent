{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mMrBwB1E1CT"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Install all dependencies\n",
        "# ==========================\n",
        "!pip install -q torchaudio omegaconf soundfile\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q groq huggingface-hub kokoro>=0.9.2 soundfile\n",
        "!apt-get -qq -y install espeak-ng > /dev/null 2>&1\n",
        "\n",
        "# ==========================\n",
        "# Imports\n",
        "# ==========================\n",
        "import os, base64, time\n",
        "import torch\n",
        "import whisper\n",
        "from google.colab import output\n",
        "from IPython.display import Javascript, display, Audio\n",
        "from groq import Groq\n",
        "from kokoro import KPipeline\n",
        "import soundfile as sf\n",
        "\n",
        "# ==========================\n",
        "# Initialize Models\n",
        "# ==========================\n",
        "print(\"ðŸ”„ Loading Whisper model...\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "whisper_model = whisper.load_model(\"medium.en\").to(DEVICE)\n",
        "\n",
        "print(\"ðŸ”„ Loading Groq client...\")\n",
        "groq_client = Groq(api_key=\"Use your Groq API Key\")\n",
        "\n",
        "print(\"ðŸ”„ Loading Kokoro TTS...\")\n",
        "tts_pipeline = KPipeline(lang_code='a')\n",
        "voice_choice = 'af_heart'\n",
        "\n",
        "# Initialize conversation\n",
        "system_message = {\"role\": \"system\", \"content\": \"You are a helpful assistant. Keep your responses concise and conversational.\"}\n",
        "conversation_history = [system_message]\n",
        "\n",
        "# Global state\n",
        "recording_counter = 0\n",
        "is_running = True\n",
        "\n",
        "print(\"\\nâœ… All models loaded successfully!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ==========================\n",
        "# Voice Chat Functions\n",
        "# ==========================\n",
        "\n",
        "def record_audio(seconds=10):\n",
        "    \"\"\"Record audio from microphone\"\"\"\n",
        "    global recording_counter\n",
        "    recording_counter += 1\n",
        "    filename = f\"/content/voice_{recording_counter}.wav\"\n",
        "\n",
        "    print(f\"\\nðŸŽ¤ Recording for {seconds} seconds... Speak now!\")\n",
        "\n",
        "    display(Javascript(f\"\"\"\n",
        "    async function recordAudio(sec) {{\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({{ audio: true }});\n",
        "      const mediaRecorder = new MediaRecorder(stream);\n",
        "      let chunks = [];\n",
        "\n",
        "      mediaRecorder.ondataavailable = e => chunks.push(e.data);\n",
        "      mediaRecorder.start();\n",
        "\n",
        "      await new Promise(r => setTimeout(r, sec * 1000));\n",
        "      mediaRecorder.stop();\n",
        "\n",
        "      await new Promise(r => mediaRecorder.onstop = r);\n",
        "\n",
        "      const blob = new Blob(chunks, {{ type: \"audio/wav\" }});\n",
        "      const reader = new FileReader();\n",
        "\n",
        "      reader.readAsDataURL(blob);\n",
        "      await new Promise(r => reader.onload = r);\n",
        "\n",
        "      google.colab.kernel.invokeFunction(\n",
        "        \"notebook.save_audio\",\n",
        "        [reader.result, \"{filename}\"],\n",
        "        {{}}\n",
        "      );\n",
        "    }}\n",
        "    recordAudio({seconds});\n",
        "    \"\"\"))\n",
        "\n",
        "def save_audio(b64_data, filename):\n",
        "    \"\"\"Save recorded audio and process it\"\"\"\n",
        "    data = base64.b64decode(b64_data.split(\",\")[1])\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(data)\n",
        "    print(f\"âœ… Recording saved: {filename} ({os.path.getsize(filename)} bytes)\")\n",
        "\n",
        "    # Process the recording\n",
        "    process_voice_input(filename)\n",
        "\n",
        "def process_voice_input(filename):\n",
        "    \"\"\"Process user voice input and generate AI response\"\"\"\n",
        "    global conversation_history, is_running\n",
        "\n",
        "    # Transcribe\n",
        "    print(\"\\nðŸ”„ Transcribing your voice...\")\n",
        "    result = whisper_model.transcribe(filename, verbose=False, language=\"en\")\n",
        "\n",
        "    user_text = result[\"text\"].strip()\n",
        "\n",
        "    # Check if recording was empty or too short\n",
        "    if not user_text or len(user_text) < 3:\n",
        "        print(\"\\nâš ï¸ No speech detected. Please try again.\")\n",
        "        time.sleep(1)\n",
        "        if is_running:\n",
        "            continue_conversation()\n",
        "        return\n",
        "\n",
        "    print(f\"\\nðŸ‘¤ You said: {user_text}\")\n",
        "\n",
        "    # Check for exit command\n",
        "    exit_keywords = [\"exit\", \"quit\", \"stop\", \"goodbye\", \"bye\"]\n",
        "    if any(keyword in user_text.lower() for keyword in exit_keywords):\n",
        "        print(\"\\nðŸ‘‹ Ending conversation. Goodbye!\")\n",
        "        is_running = False\n",
        "\n",
        "        # Generate goodbye message\n",
        "        goodbye_text = \"Goodbye! It was nice talking to you.\"\n",
        "        print(f\"\\nðŸ¤– Assistant: {goodbye_text}\")\n",
        "        generate_speech(goodbye_text)\n",
        "        return\n",
        "\n",
        "    # Add to conversation\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": user_text})\n",
        "\n",
        "    # Get LLM response\n",
        "    print(\"\\nðŸ”„ Getting AI response...\")\n",
        "    try:\n",
        "        chat_completion = groq_client.chat.completions.create(\n",
        "            messages=conversation_history,\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            max_tokens=150  # Keep responses concise\n",
        "        )\n",
        "        assistant_text = chat_completion.choices[0].message.content\n",
        "        print(f\"\\nðŸ¤– Assistant: {assistant_text}\")\n",
        "\n",
        "        # Add to conversation\n",
        "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_text})\n",
        "\n",
        "        # Generate and play speech\n",
        "        generate_speech(assistant_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Error getting AI response: {e}\")\n",
        "        is_running = False\n",
        "        return\n",
        "\n",
        "    # Continue conversation automatically\n",
        "    if is_running:\n",
        "        time.sleep(0.5)  # Short pause before next recording\n",
        "        continue_conversation()\n",
        "\n",
        "def generate_speech(text):\n",
        "    \"\"\"Generate and play TTS audio\"\"\"\n",
        "    print(\"\\nðŸ”Š Generating voice response...\")\n",
        "\n",
        "    try:\n",
        "        generator = tts_pipeline(text, voice=voice_choice)\n",
        "        total_duration = 0\n",
        "\n",
        "        for i, (gs, ps, audio) in enumerate(generator):\n",
        "            audio_file = f'/content/assistant_response_{recording_counter}_{i}.wav'\n",
        "            sf.write(audio_file, audio, 24000)\n",
        "            display(Audio(audio_file, rate=24000, autoplay=True))\n",
        "\n",
        "            # Calculate duration and wait for audio to finish\n",
        "            duration = len(audio) / 24000\n",
        "            total_duration += duration\n",
        "            time.sleep(duration + 0.2)  # Small buffer\n",
        "\n",
        "        print(f\"âœ… Voice response complete ({total_duration:.1f}s)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error generating speech: {e}\")\n",
        "\n",
        "def continue_conversation():\n",
        "    \"\"\"Continue the conversation with next recording\"\"\"\n",
        "    global is_running\n",
        "\n",
        "    if not is_running:\n",
        "        print(\"\\nâœ… Conversation ended.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"ðŸŽ¤ Your turn to speak!\")\n",
        "    print(\"ðŸ’¡ Say 'exit', 'quit', or 'goodbye' to end the conversation\")\n",
        "    print(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "    # Start next recording\n",
        "    record_audio(seconds=10)\n",
        "\n",
        "# Register callback\n",
        "output.register_callback(\"notebook.save_audio\", save_audio)\n",
        "\n",
        "# ==========================\n",
        "# Start Interactive Voice Chat\n",
        "# ==========================\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ðŸŽ™ï¸ INTERACTIVE VOICE CHAT\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\nðŸ“‹ How it works:\")\n",
        "print(\"1. You speak (10 seconds)\")\n",
        "print(\"2. AI responds with voice\")\n",
        "print(\"3. Automatically your turn again\")\n",
        "print(\"4. Say 'exit' or 'goodbye' to stop\")\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ðŸš€ Starting conversation...\")\n",
        "print(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "# Start first recording\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(1)\n",
        "record_audio(seconds=10)"
      ],
      "metadata": {
        "id": "LZdSjLhoNm_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4JoxzghbRnZv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}